# ai-pipe

Легковесное OpenAI-compatible решение для реализации plugin-based логики постпроцессинга запросов к LLM.

## Кратко

ai-pipe представляет собой FastAPI приложение, которое оперирует несколькими ключевыми понятиями:
- Профиль: набор эндпоинтов под уникальным префиксом, имеющий свой собственный набор конфигураций плагинов
- Плагин: Python класс, который работает с телом и заголовками запроса. Плагины вызываются в порядке объявления конфигураций.
- Конфиг плагина: Набор настроек, которые можно указать в секции конфигурационного файла определенного плагина. Корректность валидируется при запуске сервера.

## Сценарии использования

1. Встроенные плагины:
    - [src.plugins.builtin.static](src/plugins/builtin/static.py) реализует статичное добавление информации в заголовки и тело, перезаписывая уже существующие ключи.
2. Свои (кастомные плагины):
    - [src.plugins.abc](src/plugins/abc.py) объявляет класс `BasePlugin`, который должен наследоваться написанным плагином. Плагин загружается по имени пакета, который экспортирует классы `Plugin` и `Settings` (см. static плагин).

## Сборка

```bash
docker build . -t ai-pipe:latest
```

## Запуск
```bash
cp config.sample.yaml config.yaml
nvim config.yaml # подредактируйте конфиг под свои нужды
docker run -p 8000:8000 -v ./config.yaml:/home/app/config.yaml ai-pipe:latest
```
